{
    "nbformat_minor": 1, 
    "cells": [
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "!pip install --upgrade pixiedust\n!pip install --upgrade bokeh\n\n# pixiedust.installPackage(\"cloudant-labs:spark-cloudant:2.0.0-s_2.11\")"
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {
                "scrolled": false
            }, 
            "outputs": [], 
            "source": "import pixiedust\nimport bokeh"
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "# The code was removed by Watson Studio for sharing."
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "sparkSession = SQLContext.getOrCreate(sc).sparkSession\n\ncloudantdata=sparkSession.read.format(\"com.cloudant.spark\")\\\n  .option(\"cloudant.host\",credentials_1['host'])\\\n  .option(\"cloudant.username\", credentials_1['username'])\\\n  .option(\"cloudant.password\", credentials_1['password'])\\\n  .option(\"jsonstore.rdd.partitions\", \"1\")\\\n  .option(\"inferSchema\", \"True\")\\\n  .load(\"zzshake\")\n\ncloudantdata.createOrReplaceTempView(\"dataframe\")\ncloudantdata.printSchema"
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "sqlenergy = spark.sql(\"select cast (sum(sqrt((AX * AX) + (AY * AY) + (AZ * AZ))) as integer) as EN, ID from dataframe group by ID order by EN desc\")\nsqlenergy.show()"
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {
                "pixiedust": {
                    "displayParams": {
                        "mpld3": "false", 
                        "aggregation": "SUM", 
                        "rowCount": "500", 
                        "handlerId": "barChart", 
                        "valueFields": "EN", 
                        "rendererId": "matplotlib", 
                        "sortby": "Values DESC", 
                        "timeseries": "false", 
                        "keyFields": "ID"
                    }
                }, 
                "scrolled": true
            }, 
            "outputs": [], 
            "source": "display(sqlenergy)"
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {
                "pixiedust": {
                    "displayParams": {
                        "lineChartType": "grouped", 
                        "mpld3": "false", 
                        "aggregation": "SUM", 
                        "logx": "false", 
                        "logy": "false", 
                        "handlerId": "lineChart", 
                        "valueFields": "AX,AY,AZ", 
                        "rendererId": "matplotlib", 
                        "keyFields": "TS"
                    }
                }, 
                "scrolled": true
            }, 
            "outputs": [], 
            "source": "modeldata = spark.sql(\"select TS, ID, AX, AY, AZ, OA, OB, OG, sqrt((AX * AX) + (AY * AY) + (AZ * AZ)) as EN from dataframe\")\ndisplay(modeldata)"
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {
                "pixiedust": {
                    "displayParams": {
                        "lineChartType": "grouped", 
                        "mpld3": "false", 
                        "aggregation": "SUM", 
                        "logx": "false", 
                        "logy": "false", 
                        "clusterby": "SENSORID", 
                        "handlerId": "lineChart", 
                        "valueFields": "OA,OB,OG", 
                        "rendererId": "matplotlib", 
                        "timeseries": "false", 
                        "keyFields": "TS"
                    }
                }, 
                "scrolled": true
            }, 
            "outputs": [], 
            "source": "display(modeldata)"
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {
                "pixiedust": {
                    "displayParams": {
                        "handlerId": "tableView"
                    }
                }, 
                "scrolled": false
            }, 
            "outputs": [], 
            "source": "display(modeldata)"
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "modeldata"
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "modeldata.show()"
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "modeldata.printSchema()"
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "modeldata.describe().show()"
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "modeldata.count()"
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "split_data = modeldata.randomSplit([0.5, 0.5], 0)\ntrain_data = split_data[0]\ntest_data  = split_data[1]\n\nprint \"Number of training records : \" + str(train_data.count())\nprint \"Number of testing records  : \" + str(test_data.count())"
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "from pyspark.ml.feature import StringIndexer, IndexToString, VectorAssembler\n\nfrom pyspark.ml.classification import RandomForestClassifier\nfrom pyspark.ml.classification import DecisionTreeClassifier\nfrom pyspark.ml.classification import GBTClassifier\n\nfrom pyspark.ml.evaluation import MulticlassClassificationEvaluator\n\nfrom pyspark.ml import Pipeline, Model"
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "stringIndexer_label = StringIndexer(inputCol = \"ID\", outputCol = \"label\").fit(modeldata)\nstringIndexer_label.labels"
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "vectorAssembler_features = VectorAssembler(inputCols=[\"AX\", \"AY\", \"AZ\", \"OA\", \"OB\", \"OG\"], outputCol = \"features\")"
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "labelConverter = IndexToString(inputCol = \"prediction\", outputCol = \"predlabel\", labels = stringIndexer_label.labels)"
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "cf = RandomForestClassifier(labelCol = \"label\", featuresCol = \"features\")\n\n# cf = GBTClassifier(labelCol=\"label\", featuresCol=\"features\")"
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "pipeline_cf = Pipeline(stages = [stringIndexer_label, vectorAssembler_features, cf, labelConverter])"
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "model_cf = pipeline_cf.fit(train_data)"
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "predictions = model_cf.transform(test_data)\nevaluator = MulticlassClassificationEvaluator(labelCol = \"label\", predictionCol = \"prediction\", metricName = \"accuracy\")\naccuracy = evaluator.evaluate(predictions)\n\nprint(\"Accuracy = %g\" % accuracy)"
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {
                "scrolled": false
            }, 
            "outputs": [], 
            "source": "predictions.show()"
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {
                "pixiedust": {
                    "displayParams": {
                        "kind": "kde", 
                        "mpld3": "false", 
                        "dynamicfilter": "label", 
                        "rowCount": "1000000", 
                        "handlerId": "scatterPlot", 
                        "valueFields": "prediction", 
                        "rendererId": "seaborn", 
                        "keyFields": "label"
                    }
                }
            }, 
            "outputs": [], 
            "source": "display(predictions)"
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": ""
        }
    ], 
    "metadata": {
        "kernelspec": {
            "display_name": "Python 2 with Spark 2.1", 
            "name": "python2-spark21", 
            "language": "python"
        }, 
        "language_info": {
            "mimetype": "text/x-python", 
            "nbconvert_exporter": "python", 
            "version": "2.7.14", 
            "name": "python", 
            "file_extension": ".py", 
            "pygments_lexer": "ipython2", 
            "codemirror_mode": {
                "version": 2, 
                "name": "ipython"
            }
        }
    }, 
    "nbformat": 4
}